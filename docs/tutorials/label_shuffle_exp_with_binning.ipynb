{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Shuffle Experiment for Progressive Learning\n",
    "\n",
    "The progressive learning package utilizes representation ensembling algorithms to sequentially learn a representation for each task and ensemble both old and new representations for all future decisions. \n",
    "\n",
    "Here, a representation ensembling algorithm based on decision forests (Lifelong Forest) demonstrate forward and backward knowledge transfer of tasks on the CIFAR100 dataset with the labels shuffled. The experiment reproduces the benchmarking adversarial experiment ran in the paper \"A General Approach to Progressive Learning\" by Vogelstein, et al (2020). The following is a link to the aforementioned paper: https://arxiv.org/pdf/2004.12908.pdf  \n",
    "\n",
    "### Import necessary packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CIFAR100 data \n",
    "We load the CIFAR100 dataset from Keras, and store it in a variable. The training and test partitions are concatenated into one variable called `data_x`. The data is obtained from https://keras.io/api/datasets/cifar100/ .\n",
    "\n",
    "The label shuffle experiment randomly permutes the class labels within each task from task 2 to 10, rendering each of these tasks adversarial with regard to the first task. We show through this experiment that L2F are invariant to class lable shuffling, and both demonstrate transfer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "data_x = np.concatenate([X_train, X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters for the model and preprocess data\n",
    "Running the cells below will define the hyperparameters the experimental setting \n",
    "\n",
    "`num_points_per_task`: The number of points per task \n",
    "\n",
    "`shifts`: The number of data ways to split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_per_task = 500\n",
    "\n",
    "shifts = 2 \n",
    "\n",
    "num_slots = int(5000 // num_points_per_task)\n",
    "slot_fold = range(int(5000 // num_points_per_task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[255 255 255 ... 138 173  79]\n [255 255 255 ... 255 255 255]\n [250 250 248 ... 232 230 228]\n ...\n [178 168 176 ... 249 245 242]\n [122 159 186 ...  35  37  36]\n [255 255 255 ... 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the data \n",
    "data_x = data_x.reshape((data_x.shape[0], data_x.shape[1] * data_x.shape[2] * data_x.shape[3]))\n",
    "data_y = np.concatenate([y_train, y_test])\n",
    "data_y = data_y[:, 0]\n",
    "\n",
    "print(data_x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# Calculate optimal n_bins using Sturge's Rule\n",
    "n_bins = math.floor(1 + math.log(data_x.shape[0], 2))\n",
    "print(\"Number of bins: \" + str(n_bins))\n",
    "binner = KBinsDiscretizer(n_bins, encode='ordinal', strategy='uniform')\n",
    "binner.fit(data_x)\n",
    "data_x = binner.transform(data_x)\n",
    "print(data_x[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and perform validation\n",
    "\n",
    "#### run_parallel_exp: \n",
    "Wrapper method for the `LF_experiment` function which declares and trains the model, and performs validation with respect to the test data to compute the error of the model at a particular iteration\n",
    "\n",
    "`ntree`: Number of trees for Uncertainty Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  2.9min remaining:  1.2min\n"
     ]
    }
   ],
   "source": [
    "from functions.label_shuffle_functions import run_parallel_exp\n",
    "\n",
    "n_trees=[10] # Number of trees in UF\n",
    "\n",
    "shift_fold = range(1,shifts,1) # Number of shifts\n",
    "iterable = product(n_trees,shift_fold,slot_fold)\n",
    "\n",
    "df_list = Parallel(n_jobs=-1,verbose=1)(\n",
    "    delayed(run_parallel_exp)(\n",
    "            data_x, data_y, ntree, num_points_per_task, slot=slot, shift=shift\n",
    "            ) for ntree,shift,slot in iterable\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate backward transfer efficiency\n",
    "\n",
    "The backward transfer efficiency of $f_n$ for task $t$ given $n$ samples is \n",
    "$$BTE^t (f_n) := \\mathbb{E} [R^t (f_n^{<t} )/R^t (f_n)]$$\n",
    "\n",
    "We say an algorithm achieves backward transfer for task $t$ if and only if $BTE^t(f_n) > 1$. Intuitively, this means that the progressive learner has used data associated with new tasks to improve performance on previous tasks. \n",
    "\n",
    "#### calc_bte:\n",
    "Function used to calculate bte across tasks, averaged across all shifts and folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.label_shuffle_functions import calc_bte\n",
    "\n",
    "btes = calc_bte(df_list, num_slots, shifts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the backward transfer efficiency\n",
    "Run cell to generate plot of backward transfer efficiency of the Lifelong Classification Forest algorithm. We see that we achieve backwards transfer overall that increases as more tasks are seen.\n",
    "\n",
    "#### plot_bte:\n",
    "Function used to plot bte across tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.label_shuffle_functions import plot_bte\n",
    "\n",
    "plot_bte(btes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}